{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:52:07.820057Z",
     "start_time": "2025-04-12T22:52:05.549898Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn \n",
    "from PIL import Image, ImageFile\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, ConfusionMatrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# ignoring user warnings because it just points out the 'P' images\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:52:08.707100Z",
     "start_time": "2025-04-12T22:52:08.694309Z"
    }
   },
   "id": "86ae65564a45f573"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "if not(torch.backends.mps.is_available()): \n",
    "    device = torch.device('cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:52:09.874473Z",
     "start_time": "2025-04-12T22:52:09.865466Z"
    }
   },
   "id": "bff39e08ca362a75"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "eb3_transforms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(\n",
    "            mean=[0.485,0.456, 0.406], \n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:52:14.057364Z",
     "start_time": "2025-04-12T22:52:14.053618Z"
    }
   },
   "id": "9b358e0ab574c369"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "class CustomDataset(ImageFolder): \n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root, transform=None)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        path, label = self.samples[idx]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', Image.DecompressionBombWarning)\n",
    "\n",
    "            try:\n",
    "                image = Image.open(path).convert('RGB')\n",
    "                \n",
    "            except Image.DecompressionBombWarning:\n",
    "                print(f'Decompression Bomb Warning at {path}')\n",
    "                raise IndexError(f'Skipping {path} because decompression warning')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('PATH = ', path)    \n",
    "                \n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # label manipulation \n",
    "        label = torch.tensor(label)\n",
    "        label = nn.functional.one_hot(label, num_classes=2)\n",
    "            \n",
    "        return image, label\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:52:15.060026Z",
     "start_time": "2025-04-12T22:52:15.051559Z"
    }
   },
   "id": "c34b14e9b75393db"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_link = \"datasets/30 k datapoints/train\"\n",
    "\n",
    "dataset = CustomDataset(root = train_link, transform=eb3_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T23:13:59.238898Z",
     "start_time": "2025-04-07T23:13:59.150214Z"
    }
   },
   "id": "26eb1cd1b1f3cdf"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = int(0.8 * len(dataset)) \n",
    "train, val = random_split(dataset= dataset, lengths=[TRAIN_SPLIT, len(dataset) - TRAIN_SPLIT])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T23:13:59.650077Z",
     "start_time": "2025-04-07T23:13:59.643810Z"
    }
   },
   "id": "d43dbcfd49149b8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "TrainLoader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "ValLoader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T23:14:00.020586Z",
     "start_time": "2025-04-07T23:14:00.015678Z"
    }
   },
   "id": "f81613fa8c2f834b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "torch.Size([32, 3, 224, 224]) tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# printing shapes and testing \n",
    "for images, labels in TrainLoader: \n",
    "    print(images.shape, labels)\n",
    "    break\n",
    "\n",
    "for image, label in ValLoader: \n",
    "    print(image.shape, label)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T20:47:42.246329Z",
     "start_time": "2025-04-07T20:47:38.497917Z"
    }
   },
   "id": "90167daed1cf8feb"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class EB3(nn.Module): \n",
    "    def __init__(self, fine_tune = False):\n",
    "        super(EB3, self).__init__()\n",
    "        \n",
    "        # load pretrained model \n",
    "        self.eb3 = models.efficientnet_b3(weights = 'DEFAULT')\n",
    "        \n",
    "        # freeze the vgg 16 \n",
    "        if not(fine_tune): \n",
    "            for params in self.eb3.parameters(): \n",
    "                params.requires_grad = False\n",
    "        \n",
    "        self.eb3.classifier = nn.Sequential(\n",
    "                nn.Linear(self.eb3.classifier[1].in_features, 2048),\n",
    "                nn.BatchNorm1d(num_features=2048), \n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.ReLU(), \n",
    "                nn.Linear(2048, 1024),\n",
    "                nn.BatchNorm1d(num_features=1024),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.ReLU(), \n",
    "                nn.Linear(1024, 2), \n",
    "        )\n",
    "        \n",
    "        # making classifier segment trainable \n",
    "        for params in self.eb3.classifier.parameters(): \n",
    "            params.requires_grad = True\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.eb3(x)\n",
    "    \n",
    "    def get_prediction(self, x):\n",
    "        outputs = self.forward(x)\n",
    "        outputs = torch.softmax(outputs)\n",
    "        return torch.argmax(outputs)\n",
    "        \n",
    "        \n",
    "    def StartFineTuning(self, blocks_to_unfreeze=7): \n",
    "        ''' unfreeze the last block and train that as well \n",
    "        do this only when you train the classifier model \n",
    "        '''\n",
    "        \n",
    "        for idx in range(blocks_to_unfreeze, len(self.eb3.features)):\n",
    "            for param in self.eb3.features[idx].parameters():\n",
    "                param.requires_grad = True\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:52:21.037030Z",
     "start_time": "2025-04-12T22:52:21.028776Z"
    }
   },
   "id": "e203fad1ec107abe"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = EB3().to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T23:14:33.674674Z",
     "start_time": "2025-04-07T23:14:33.317910Z"
    }
   },
   "id": "7e33fe20c94fe321"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─EfficientNet: 1-1                           --\n",
      "|    └─Sequential: 2-1                        --\n",
      "|    |    └─Conv2dNormActivation: 3-1         (1,160)\n",
      "|    |    └─Sequential: 3-2                   (3,504)\n",
      "|    |    └─Sequential: 3-3                   (48,118)\n",
      "|    |    └─Sequential: 3-4                   (110,912)\n",
      "|    |    └─Sequential: 3-5                   (638,700)\n",
      "|    |    └─Sequential: 3-6                   (1,387,760)\n",
      "|    |    └─Sequential: 3-7                   (4,628,964)\n",
      "|    |    └─Sequential: 3-8                   (3,284,218)\n",
      "|    |    └─Conv2dNormActivation: 3-9         (592,896)\n",
      "|    └─AdaptiveAvgPool2d: 2-2                 --\n",
      "|    └─Sequential: 2-3                        --\n",
      "|    |    └─Linear: 3-10                      3,147,776\n",
      "|    |    └─BatchNorm1d: 3-11                 4,096\n",
      "|    |    └─Dropout: 3-12                     --\n",
      "|    |    └─ReLU: 3-13                        --\n",
      "|    |    └─Linear: 3-14                      2,098,176\n",
      "|    |    └─BatchNorm1d: 3-15                 2,048\n",
      "|    |    └─Dropout: 3-16                     --\n",
      "|    |    └─ReLU: 3-17                        --\n",
      "|    |    └─Linear: 3-18                      2,050\n",
      "======================================================================\n",
      "Total params: 15,950,378\n",
      "Trainable params: 5,254,146\n",
      "Non-trainable params: 10,696,232\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T23:14:33.689072Z",
     "start_time": "2025-04-07T23:14:33.683673Z"
    }
   },
   "id": "43c554f03f720fdc"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def train_eb3(TrainLoader, ValLoader, model, EPOCHS = 5):\n",
    "    \n",
    "    # model parameters definition\n",
    "    lossfn = torch.nn.CrossEntropyLoss()\n",
    "    LEARNING_RATE = 1E-3\n",
    "    opt = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    \n",
    "    # accuracy \n",
    "    accuracy = Accuracy(task='multiclass', num_classes=2).to(device=device)\n",
    "    \n",
    "    # training segment\n",
    "    training_loss_list = []\n",
    "    val_loss_list = []\n",
    "    for epoch in range(EPOCHS): \n",
    "        running_loss = 0\n",
    "        TrainLoader_tqdm = tqdm(TrainLoader)\n",
    "        for image, label in TrainLoader_tqdm:\n",
    "            \n",
    "            \n",
    "            # moving labels and images to GPU\n",
    "            image = image.to(device=device)\n",
    "            label = label.to(device=device)\n",
    "        \n",
    "            opt.zero_grad()\n",
    "        \n",
    "            # predicting and training \n",
    "            output = model(image)\n",
    "            loss = lossfn(output.squeeze(1), label.float())\n",
    "            loss.backward()\n",
    "            running_loss += loss.item() / len(TrainLoader)\n",
    "            \n",
    "            accuracy.update(output.squeeze(1), label.argmax(dim=1))\n",
    "            TrainLoader_tqdm.set_postfix({\"Training Loss\": running_loss})\n",
    "            opt.step()\n",
    "            \n",
    "        train_accuracy = accuracy.compute().item()\n",
    "        accuracy.reset()\n",
    "        \n",
    "        # storing train loss \n",
    "        training_loss_list.append(running_loss)\n",
    "        \n",
    "        # print progress bar \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # validation segment\n",
    "        val_running_loss = 0\n",
    "        for image, label in ValLoader: \n",
    "            image = image.to(device = device)\n",
    "            label = label.to(device = device)\n",
    "            \n",
    "            # model output\n",
    "            output = model(image)\n",
    "            \n",
    "            # loss computation\n",
    "            loss = lossfn(output.squeeze(1), label.float())\n",
    "            val_running_loss += loss.item() / len(ValLoader)\n",
    "            \n",
    "            # accuracy computation\n",
    "            accuracy.update(output.squeeze(1), label.argmax(dim=1))\n",
    "        \n",
    "        # validation loss storing \n",
    "        val_loss_list.append(val_running_loss)\n",
    "    \n",
    "        # final accuracy calculations \n",
    "        val_accuracy = accuracy.compute().item()\n",
    "        accuracy.reset()\n",
    "        \n",
    "        # printing metrics\n",
    "        print(f'''epoch [{epoch+1}/{EPOCHS}]\n",
    "        \\t training loss: {running_loss},\n",
    "        \\t validation loss: {val_running_loss},\n",
    "        \\t Train Accuracy: {train_accuracy},\n",
    "        \\t Val acc: {val_accuracy},\n",
    "            ''')\n",
    "    \n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T23:15:04.219081Z",
     "start_time": "2025-04-07T23:15:04.214359Z"
    }
   },
   "id": "154a29dfc05622c2"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [40:11<00:00,  2.01s/it, Training Loss=0.338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5]\n",
      "        \t training loss: 0.3383557503173749,\n",
      "        \t validation loss: 0.3021835667143265,\n",
      "        \t Train Accuracy: 0.8526822924613953,\n",
      "        \t Val acc: 0.8710416555404663,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [39:03<00:00,  1.95s/it, Training Loss=0.228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [2/5]\n",
      "        \t training loss: 0.22821002292602016,\n",
      "        \t validation loss: 0.3003210776795944,\n",
      "        \t Train Accuracy: 0.9076041579246521,\n",
      "        \t Val acc: 0.879895806312561,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [39:09<00:00,  1.96s/it, Training Loss=0.132] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [3/5]\n",
      "        \t training loss: 0.13167853456068151,\n",
      "        \t validation loss: 0.3400500608359773,\n",
      "        \t Train Accuracy: 0.948437511920929,\n",
      "        \t Val acc: 0.8810416460037231,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [39:08<00:00,  1.96s/it, Training Loss=0.0703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/5]\n",
      "        \t training loss: 0.07034948261736038,\n",
      "        \t validation loss: 0.44281514861931404,\n",
      "        \t Train Accuracy: 0.9731770753860474,\n",
      "        \t Val acc: 0.8809375166893005,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [38:40<00:00,  1.93s/it, Training Loss=0.0468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [5/5]\n",
      "        \t training loss: 0.046760336955242905,\n",
      "        \t validation loss: 0.5168238785148901,\n",
      "        \t Train Accuracy: 0.9828645586967468,\n",
      "        \t Val acc: 0.8785416483879089,\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = train_eb3(TrainLoader, ValLoader, model, EPOCHS=EPOCHS)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T03:18:55.193295Z",
     "start_time": "2025-04-07T23:15:05.357360Z"
    }
   },
   "id": "44d027947fdbf369"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "torch.save(model, './saved models/EB3_no_finetune.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T03:20:00.534897Z",
     "start_time": "2025-04-08T03:20:00.286196Z"
    }
   },
   "id": "2654fd2950f376fc"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─EfficientNet: 1-1                           --\n",
      "|    └─Sequential: 2-1                        --\n",
      "|    |    └─Conv2dNormActivation: 3-1         (1,160)\n",
      "|    |    └─Sequential: 3-2                   (3,504)\n",
      "|    |    └─Sequential: 3-3                   (48,118)\n",
      "|    |    └─Sequential: 3-4                   (110,912)\n",
      "|    |    └─Sequential: 3-5                   (638,700)\n",
      "|    |    └─Sequential: 3-6                   (1,387,760)\n",
      "|    |    └─Sequential: 3-7                   (4,628,964)\n",
      "|    |    └─Sequential: 3-8                   3,284,218\n",
      "|    |    └─Conv2dNormActivation: 3-9         592,896\n",
      "|    └─AdaptiveAvgPool2d: 2-2                 --\n",
      "|    └─Sequential: 2-3                        --\n",
      "|    |    └─Linear: 3-10                      3,147,776\n",
      "|    |    └─BatchNorm1d: 3-11                 4,096\n",
      "|    |    └─Dropout: 3-12                     --\n",
      "|    |    └─ReLU: 3-13                        --\n",
      "|    |    └─Linear: 3-14                      2,098,176\n",
      "|    |    └─BatchNorm1d: 3-15                 2,048\n",
      "|    |    └─Dropout: 3-16                     --\n",
      "|    |    └─ReLU: 3-17                        --\n",
      "|    |    └─Linear: 3-18                      2,050\n",
      "======================================================================\n",
      "Total params: 15,950,378\n",
      "Trainable params: 9,131,260\n",
      "Non-trainable params: 6,819,118\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# fine tuning segment \n",
    "model.StartFineTuning(blocks_to_unfreeze=7)\n",
    "summary(model);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T03:28:26.675219Z",
     "start_time": "2025-04-08T03:28:26.671113Z"
    }
   },
   "id": "cf2f6fc74395ea60"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [39:44<00:00,  1.99s/it, Training Loss=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5]\n",
      "        \t training loss: 0.23395919434726276,\n",
      "        \t validation loss: 0.22540919076651353,\n",
      "        \t Train Accuracy: 0.9095051884651184,\n",
      "        \t Val acc: 0.9069791436195374,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [39:44<00:00,  1.99s/it, Training Loss=0.144] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [2/5]\n",
      "        \t training loss: 0.14427097119429783,\n",
      "        \t validation loss: 0.20518042450149845,\n",
      "        \t Train Accuracy: 0.9459114670753479,\n",
      "        \t Val acc: 0.9205208420753479,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [39:32<00:00,  1.98s/it, Training Loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [3/5]\n",
      "        \t training loss: 0.1070098492623463,\n",
      "        \t validation loss: 0.2034753813827409,\n",
      "        \t Train Accuracy: 0.960364580154419,\n",
      "        \t Val acc: 0.9311458468437195,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [39:42<00:00,  1.99s/it, Training Loss=0.0774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/5]\n",
      "        \t training loss: 0.077424864441297,\n",
      "        \t validation loss: 0.21933525675286858,\n",
      "        \t Train Accuracy: 0.9712499976158142,\n",
      "        \t Val acc: 0.9248958230018616,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [39:39<00:00,  1.98s/it, Training Loss=0.0589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [5/5]\n",
      "        \t training loss: 0.05886936199664588,\n",
      "        \t validation loss: 0.21604542025908194,\n",
      "        \t Train Accuracy: 0.9786978960037231,\n",
      "        \t Val acc: 0.9336458444595337,\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "model = train_eb3(TrainLoader, ValLoader, model, EPOCHS=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T07:35:05.396291Z",
     "start_time": "2025-04-08T03:28:47.980838Z"
    }
   },
   "id": "42abd06220b451a4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./saved models/eb3_finetuned.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model, './saved models/eb3_finetuned.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:53:21.490933Z",
     "start_time": "2025-04-12T22:53:21.322742Z"
    }
   },
   "id": "463a1ac674fa3b6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing phase"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fbd75965230ac38"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "testlink = \"datasets/30 k datapoints/test\"\n",
    "testset = CustomDataset(root= testlink, transform=eb3_transforms)\n",
    "TestLoader = DataLoader(testset, shuffle=False, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T16:15:54.443266Z",
     "start_time": "2025-04-08T16:15:54.405432Z"
    }
   },
   "id": "5348c7aec4708f"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [12:59<00:00,  2.08s/it, Loss=0.207] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "running_loss = 0\n",
    "\n",
    "# for metrics\n",
    "accuracy = Accuracy(task='multiclass', num_classes=2).to(device=device)\n",
    "precision = Precision(task='multiclass', num_classes=2).to(device=device)\n",
    "recall = Recall(task='multiclass', num_classes=2).to(device=device)\n",
    "ConMat = ConfusionMatrix(task='multiclass', num_classes=2).to(device=device)\n",
    "\n",
    "# loss function \n",
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# testing phase\n",
    "TestLoader_tqdm = tqdm(TestLoader)\n",
    "model.eval()\n",
    "for image, label in TestLoader_tqdm: \n",
    "    image = image.to(device= device)\n",
    "    label = label.to(device=device)\n",
    "    \n",
    "    output = model(image)\n",
    "    \n",
    "    loss = lossfn(output, label.float())\n",
    "    running_loss += loss.item() / len(TestLoader)\n",
    "    \n",
    "    TestLoader_tqdm.set_postfix({'Loss':running_loss})\n",
    "    \n",
    "    accuracy.update(output, label.argmax(dim=1))\n",
    "    precision.update(output, label.argmax(dim=1))\n",
    "    recall.update(output, label.argmax(dim=1))\n",
    "    ConMat.update(output, label.argmax(dim=1))\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T16:38:29.819234Z",
     "start_time": "2025-04-08T16:25:30.706311Z"
    }
   },
   "id": "5c41a552c8a42335"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.9354166388511658]\n",
      "    \t Test loss: 0.20656023084372266,\n",
      "    \t Precision: 0.9354166388511658,\n",
      "    \t Recall: 0.9354166388511658,\n",
      "    \t \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f'''Accuracy [{accuracy.compute()}]\n",
    "    \\t Test loss: {running_loss},\n",
    "    \\t Precision: {precision.compute()},\n",
    "    \\t Recall: {recall.compute()},\n",
    "    \\t \n",
    "        ''')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T21:00:49.502694Z",
     "start_time": "2025-04-08T21:00:49.466091Z"
    }
   },
   "id": "94e201bae63cfe41"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5574,  426],\n        [ 349, 5651]], device='mps:0')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConMat.compute()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T21:01:13.818550Z",
     "start_time": "2025-04-08T21:01:13.791033Z"
    }
   },
   "id": "ad8a6ec82d47ff4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9531384538f0b00d"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    \"\"\"\n",
    "    Opens and displays an image using the Pillow library.\n",
    "    \"\"\"\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # optional: turn off axis\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T06:33:18.900737Z",
     "start_time": "2025-04-10T06:33:18.889179Z"
    }
   },
   "id": "2e9fbc454bf4cba3"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def inverse_normalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "    return tensor * std + mean\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T06:29:07.823041Z",
     "start_time": "2025-04-10T06:29:07.812170Z"
    }
   },
   "id": "ce7faabc0a15f985"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model = torch.load('./saved models/EB3_finetuned.pt').to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:53:45.861789Z",
     "start_time": "2025-04-12T22:53:45.703031Z"
    }
   },
   "id": "21c1e34b526832d8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "link = './datasets/real life/'\n",
    "BATCH_SIZE = 32\n",
    "randomTestSet = CustomDataset(root = link, transform=eb3_transforms)\n",
    "TestLoader = DataLoader(randomTestSet, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:54:35.908615Z",
     "start_time": "2025-04-12T22:54:35.905606Z"
    }
   },
   "id": "88abc4b8ca61b129"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.52it/s, Loss=1.31]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "running_loss = 0\n",
    "\n",
    "# for metrics\n",
    "accuracy = Accuracy(task='multiclass', num_classes=2).to(device=device)\n",
    "precision = Precision(task='multiclass', num_classes=2).to(device=device)\n",
    "recall = Recall(task='multiclass', num_classes=2).to(device=device)\n",
    "ConMat = ConfusionMatrix(task='multiclass', num_classes=2).to(device=device)\n",
    "\n",
    "accuracy.reset()\n",
    "precision.reset()\n",
    "recall.reset()\n",
    "ConMat.reset()\n",
    "# loss function \n",
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# testing phase\n",
    "TestLoader_tqdm = tqdm(TestLoader)\n",
    "model.eval()\n",
    "for idx, (image, label) in enumerate(TestLoader_tqdm):\n",
    "    image = image.to(device= device)\n",
    "    label = label.to(device=device)\n",
    "\n",
    "    output = model(image)\n",
    "    \n",
    "    loss = lossfn(output, label.float())\n",
    "    running_loss += loss.item() / len(TestLoader)\n",
    "\n",
    "    TestLoader_tqdm.set_postfix({'Loss':running_loss})\n",
    "\n",
    "    accuracy.update(output, label.argmax(dim=1))\n",
    "    precision.update(output, label.argmax(dim=1))\n",
    "    recall.update(output, label.argmax(dim=1))\n",
    "    ConMat.update(output, label.argmax(dim=1))\n",
    "    \n",
    "    \n",
    "    if idx == 100: \n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:54:43.923762Z",
     "start_time": "2025-04-12T22:54:43.224325Z"
    }
   },
   "id": "9617d7836322988b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.6666666865348816]\n",
      "    \t Test loss: 1.3144327402114868,\n",
      "    \t Precision: 0.6666666865348816,\n",
      "    \t Recall: 0.6666666865348816,\n",
      "    \t \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f'''Accuracy [{accuracy.compute()}]\n",
    "    \\t Test loss: {running_loss},\n",
    "    \\t Precision: {precision.compute()},\n",
    "    \\t Recall: {recall.compute()},\n",
    "    \\t \n",
    "        ''')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:54:45.280061Z",
     "start_time": "2025-04-12T22:54:45.253511Z"
    }
   },
   "id": "69e1f50b54b5ebfa"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 0],\n        [1, 0]], device='mps:0')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConMat.compute()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T22:54:46.584999Z",
     "start_time": "2025-04-12T22:54:46.579425Z"
    }
   },
   "id": "e7c2398c6cb25834"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3345a607b4441f38"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

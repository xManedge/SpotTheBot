{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:04:48.598110Z",
     "start_time": "2025-04-10T07:04:46.496021Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn \n",
    "from PIL import Image, ImageFile\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, ConfusionMatrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# ignoring user warnings because it just points out the 'P' images\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:04:48.602512Z",
     "start_time": "2025-04-10T07:04:48.598604Z"
    }
   },
   "id": "86ae65564a45f573"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "if not(torch.backends.mps.is_available()): \n",
    "    device = torch.device('cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:04:49.862516Z",
     "start_time": "2025-04-10T07:04:49.859907Z"
    }
   },
   "id": "bff39e08ca362a75"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "swin_transforms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(\n",
    "            mean=[0.485,0.456, 0.406], \n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:04:51.140308Z",
     "start_time": "2025-04-10T07:04:51.134663Z"
    }
   },
   "id": "9b358e0ab574c369"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "class CustomDataset(ImageFolder): \n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root, transform=None)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        path, label = self.samples[idx]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', Image.DecompressionBombWarning)\n",
    "\n",
    "            try:\n",
    "                image = Image.open(path).convert('RGB')\n",
    "                \n",
    "            except Image.DecompressionBombWarning:\n",
    "                print(f'Decompression Bomb Warning at {path}')\n",
    "                raise IndexError(f'Skipping {path} because decompression warning')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('PATH = ', path)    \n",
    "                \n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # label manipulation \n",
    "        label = torch.tensor(label)\n",
    "        label = nn.functional.one_hot(label, num_classes=2)\n",
    "            \n",
    "        return image, label\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:04:51.813216Z",
     "start_time": "2025-04-10T07:04:51.806461Z"
    }
   },
   "id": "c34b14e9b75393db"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_link = \"datasets/30 k datapoints/train\"\n",
    "\n",
    "dataset = CustomDataset(root = train_link, transform=swin_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T01:28:36.338990Z",
     "start_time": "2025-04-10T01:28:36.254224Z"
    }
   },
   "id": "26eb1cd1b1f3cdf"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = int(0.8 * len(dataset)) \n",
    "train, val = random_split(dataset= dataset, lengths=[TRAIN_SPLIT, len(dataset) - TRAIN_SPLIT])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T01:28:36.339235Z",
     "start_time": "2025-04-10T01:28:36.324257Z"
    }
   },
   "id": "d43dbcfd49149b8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "TrainLoader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "ValLoader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T01:28:36.339351Z",
     "start_time": "2025-04-10T01:28:36.330117Z"
    }
   },
   "id": "f81613fa8c2f834b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "torch.Size([32, 3, 224, 224]) tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# printing shapes and testing \n",
    "for images, labels in TrainLoader: \n",
    "    print(images.shape, labels)\n",
    "    break\n",
    "\n",
    "for image, label in ValLoader: \n",
    "    print(image.shape, label)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T20:47:42.246329Z",
     "start_time": "2025-04-07T20:47:38.497917Z"
    }
   },
   "id": "90167daed1cf8feb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SWIN(nn.Module): \n",
    "    def __init__(self, fine_tune = False):\n",
    "        super(SWIN, self).__init__()\n",
    "        \n",
    "        # load pretrained model \n",
    "        self.swin = models.swin_v2_t(weights = 'DEFAULT')\n",
    "        \n",
    "        # freeze the vgg 16 \n",
    "        if not(fine_tune): \n",
    "            for params in self.swin.parameters(): \n",
    "                params.requires_grad = False\n",
    "        \n",
    "        self.swin.head = nn.Sequential(\n",
    "                nn.Linear(self.swin.head.in_features, 256),\n",
    "                nn.BatchNorm1d(num_features=256), \n",
    "                nn.Dropout(p=0.6),\n",
    "                nn.ReLU(), \n",
    "                nn.Linear(256, 2), \n",
    "        )\n",
    "        \n",
    "        # making classifier segment trainable \n",
    "        for params in self.swin.head.parameters(): \n",
    "            params.requires_grad = True\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.swin(x)\n",
    "    \n",
    "    def get_prediction(self, x):\n",
    "        outputs = self.forward(x)\n",
    "        outputs = torch.softmax(outputs)\n",
    "        return torch.argmax(outputs)\n",
    "        \n",
    "        \n",
    "    def StartFineTuning(self, blocks_to_unfreeze=4): \n",
    "        ''' unfreeze the last block and train that as well \n",
    "        do this only when you train the classifier model \n",
    "        '''\n",
    "        \n",
    "        for idx in range(blocks_to_unfreeze, 4):\n",
    "            for param in self.swin.features[idx].parameters():\n",
    "                param.requires_grad = True\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:04:54.734961Z",
     "start_time": "2025-04-10T07:04:54.728983Z"
    }
   },
   "id": "e203fad1ec107abe"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/swin_v2_t-b137f0e2.pth\" to /Users/manedge/.cache/torch/hub/checkpoints/swin_v2_t-b137f0e2.pth\n",
      "100%|██████████| 109M/109M [00:03<00:00, 37.9MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = SWIN().to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T01:28:50.992038Z",
     "start_time": "2025-04-10T01:28:46.963541Z"
    }
   },
   "id": "7e33fe20c94fe321"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "SWIN(\n  (swin): SwinTransformer(\n    (features): Sequential(\n      (0): Sequential(\n        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n        (1): Permute()\n        (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n      )\n      (1): Sequential(\n        (0): SwinTransformerBlockV2(\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=3, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=96, out_features=384, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=384, out_features=96, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): SwinTransformerBlockV2(\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=3, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=96, out_features=384, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=384, out_features=96, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (2): PatchMergingV2(\n        (reduction): Linear(in_features=384, out_features=192, bias=False)\n        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      )\n      (3): Sequential(\n        (0): SwinTransformerBlockV2(\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=6, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=192, out_features=768, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=768, out_features=192, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): SwinTransformerBlockV2(\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=6, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=192, out_features=768, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=768, out_features=192, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (4): PatchMergingV2(\n        (reduction): Linear(in_features=768, out_features=384, bias=False)\n        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      )\n      (5): Sequential(\n        (0): SwinTransformerBlockV2(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=12, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=384, out_features=1536, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=1536, out_features=384, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): SwinTransformerBlockV2(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=12, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=384, out_features=1536, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=1536, out_features=384, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (2): SwinTransformerBlockV2(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=12, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=384, out_features=1536, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=1536, out_features=384, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (3): SwinTransformerBlockV2(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=12, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=384, out_features=1536, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=1536, out_features=384, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (4): SwinTransformerBlockV2(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=12, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=384, out_features=1536, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=1536, out_features=384, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (5): SwinTransformerBlockV2(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=12, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=384, out_features=1536, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=1536, out_features=384, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (6): PatchMergingV2(\n        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (7): Sequential(\n        (0): SwinTransformerBlockV2(\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=24, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): SwinTransformerBlockV2(\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): ShiftedWindowAttentionV2(\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (cpb_mlp): Sequential(\n              (0): Linear(in_features=2, out_features=512, bias=True)\n              (1): ReLU(inplace=True)\n              (2): Linear(in_features=512, out_features=24, bias=False)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLP(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n    )\n    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (permute): Permute()\n    (avgpool): AdaptiveAvgPool2d(output_size=1)\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n    (head): Sequential(\n      (0): Linear(in_features=768, out_features=256, bias=True)\n      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Dropout(p=0.6, inplace=False)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T01:28:52.058573Z",
     "start_time": "2025-04-10T01:28:52.050391Z"
    }
   },
   "id": "c891f2fea19dc060"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "├─SwinTransformer: 1-1                             --\n",
      "|    └─Sequential: 2-1                             --\n",
      "|    |    └─Sequential: 3-1                        (4,896)\n",
      "|    |    └─Sequential: 3-2                        (229,830)\n",
      "|    |    └─PatchMergingV2: 3-3                    (74,112)\n",
      "|    |    └─Sequential: 3-4                        (898,956)\n",
      "|    |    └─PatchMergingV2: 3-5                    (295,680)\n",
      "|    |    └─Sequential: 3-6                        (10,692,936)\n",
      "|    |    └─PatchMergingV2: 3-7                    (1,181,184)\n",
      "|    |    └─Sequential: 3-8                        (14,203,440)\n",
      "|    └─LayerNorm: 2-2                              (1,536)\n",
      "|    └─Permute: 2-3                                --\n",
      "|    └─AdaptiveAvgPool2d: 2-4                      --\n",
      "|    └─Flatten: 2-5                                --\n",
      "|    └─Sequential: 2-6                             --\n",
      "|    |    └─Linear: 3-9                            196,864\n",
      "|    |    └─BatchNorm1d: 3-10                      512\n",
      "|    |    └─Dropout: 3-11                          --\n",
      "|    |    └─ReLU: 3-12                             --\n",
      "|    |    └─Linear: 3-13                           514\n",
      "===========================================================================\n",
      "Total params: 27,780,460\n",
      "Trainable params: 197,890\n",
      "Non-trainable params: 27,582,570\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T01:29:02.208722Z",
     "start_time": "2025-04-10T01:29:02.203398Z"
    }
   },
   "id": "43c554f03f720fdc"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_swin(TrainLoader, ValLoader, model, EPOCHS = 5):\n",
    "    \n",
    "    # model parameters definition\n",
    "    lossfn = torch.nn.CrossEntropyLoss()\n",
    "    LEARNING_RATE = 1E-3\n",
    "    opt = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    \n",
    "    # accuracy \n",
    "    accuracy = Accuracy(task='multiclass', num_classes=2).to(device=device)\n",
    "    \n",
    "    # training segment\n",
    "    training_loss_list = []\n",
    "    val_loss_list = []\n",
    "    for epoch in range(EPOCHS): \n",
    "        running_loss = 0\n",
    "        TrainLoader_tqdm = tqdm(TrainLoader)\n",
    "        for image, label in TrainLoader_tqdm:\n",
    "            \n",
    "            \n",
    "            # moving labels and images to GPU\n",
    "            image = image.to(device=device)\n",
    "            label = label.to(device=device)\n",
    "        \n",
    "            opt.zero_grad()\n",
    "        \n",
    "            # predicting and training \n",
    "            output = model(image)\n",
    "            loss = lossfn(output.squeeze(1), label.float())\n",
    "            loss.backward()\n",
    "            running_loss += loss.item() / len(TrainLoader)\n",
    "            \n",
    "            accuracy.update(output.squeeze(1), label.argmax(dim=1))\n",
    "            TrainLoader_tqdm.set_postfix({\"Training Loss\": running_loss})\n",
    "            opt.step()\n",
    "            \n",
    "        train_accuracy = accuracy.compute().item()\n",
    "        accuracy.reset()\n",
    "        \n",
    "        # storing train loss \n",
    "        training_loss_list.append(running_loss)\n",
    "        \n",
    "        # print progress bar \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # validation segment\n",
    "        val_running_loss = 0\n",
    "        for image, label in ValLoader: \n",
    "            image = image.to(device = device)\n",
    "            label = label.to(device = device)\n",
    "            \n",
    "            # model output\n",
    "            output = model(image)\n",
    "            \n",
    "            # loss computation\n",
    "            loss = lossfn(output.squeeze(1), label.float())\n",
    "            val_running_loss += loss.item() / len(ValLoader)\n",
    "            \n",
    "            # accuracy computation\n",
    "            accuracy.update(output.squeeze(1), label.argmax(dim=1))\n",
    "        \n",
    "        # validation loss storing \n",
    "        val_loss_list.append(val_running_loss)\n",
    "    \n",
    "        # final accuracy calculations \n",
    "        val_accuracy = accuracy.compute().item()\n",
    "        accuracy.reset()\n",
    "        \n",
    "        # printing metrics\n",
    "        print(f'''epoch [{epoch+1}/{EPOCHS}]\n",
    "        \\t training loss: {running_loss},\n",
    "        \\t validation loss: {val_running_loss},\n",
    "        \\t Train Accuracy: {train_accuracy},\n",
    "        \\t Val acc: {val_accuracy},\n",
    "            ''')\n",
    "    \n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T01:29:05.712828Z",
     "start_time": "2025-04-10T01:29:05.707861Z"
    }
   },
   "id": "154a29dfc05622c2"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [42:20<00:00,  2.12s/it, Training Loss=0.266]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5]\n",
      "        \t training loss: 0.26564220673094224,\n",
      "        \t validation loss: 0.22959856534997627,\n",
      "        \t Train Accuracy: 0.8905468583106995,\n",
      "        \t Val acc: 0.9078124761581421,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [42:36<00:00,  2.13s/it, Training Loss=0.173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [2/5]\n",
      "        \t training loss: 0.1729116088128648,\n",
      "        \t validation loss: 0.20733012164632492,\n",
      "        \t Train Accuracy: 0.9341145753860474,\n",
      "        \t Val acc: 0.9190624952316284,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [42:49<00:00,  2.14s/it, Training Loss=0.11]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [3/5]\n",
      "        \t training loss: 0.10988528079353259,\n",
      "        \t validation loss: 0.21978169227639843,\n",
      "        \t Train Accuracy: 0.9595833420753479,\n",
      "        \t Val acc: 0.918749988079071,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [42:51<00:00,  2.14s/it, Training Loss=0.0644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/5]\n",
      "        \t training loss: 0.06441883566944556,\n",
      "        \t validation loss: 0.25049035825145727,\n",
      "        \t Train Accuracy: 0.9780208468437195,\n",
      "        \t Val acc: 0.9201041460037231,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [42:48<00:00,  2.14s/it, Training Loss=0.042] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [5/5]\n",
      "        \t training loss: 0.042004853563630595,\n",
      "        \t validation loss: 0.31358435168707127,\n",
      "        \t Train Accuracy: 0.9860156178474426,\n",
      "        \t Val acc: 0.910729169845581,\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = train_swin(TrainLoader, ValLoader, model, EPOCHS=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T05:56:21.769498Z",
     "start_time": "2025-04-10T01:29:10.107312Z"
    }
   },
   "id": "44d027947fdbf369"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "torch.save(model, './saved models/swin_T_no_finetune.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T05:56:21.996903Z",
     "start_time": "2025-04-10T05:56:21.781190Z"
    }
   },
   "id": "2654fd2950f376fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4868e90f8cb6d53f"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "├─SwinTransformer: 1-1                             --\n",
      "|    └─Sequential: 2-1                             --\n",
      "|    |    └─Sequential: 3-1                        (4,896)\n",
      "|    |    └─Sequential: 3-2                        (224,694)\n",
      "|    |    └─PatchMerging: 3-3                      (74,496)\n",
      "|    |    └─Sequential: 3-4                        891,756\n",
      "|    |    └─PatchMerging: 3-5                      (296,448)\n",
      "|    |    └─Sequential: 3-6                        (31,976,856)\n",
      "|    |    └─PatchMerging: 3-7                      (1,182,720)\n",
      "|    |    └─Sequential: 3-8                        (14,183,856)\n",
      "|    └─LayerNorm: 2-2                              (1,536)\n",
      "|    └─Permute: 2-3                                --\n",
      "|    └─AdaptiveAvgPool2d: 2-4                      --\n",
      "|    └─Flatten: 2-5                                --\n",
      "|    └─Sequential: 2-6                             --\n",
      "|    |    └─Linear: 3-9                            196,864\n",
      "|    |    └─BatchNorm1d: 3-10                      512\n",
      "|    |    └─Dropout: 3-11                          --\n",
      "|    |    └─ReLU: 3-12                             --\n",
      "|    |    └─Linear: 3-13                           32,896\n",
      "|    |    └─BatchNorm1d: 3-14                      256\n",
      "|    |    └─Dropout: 3-15                          --\n",
      "|    |    └─ReLU: 3-16                             --\n",
      "|    |    └─Linear: 3-17                           258\n",
      "===========================================================================\n",
      "Total params: 49,068,044\n",
      "Trainable params: 1,122,542\n",
      "Non-trainable params: 47,945,502\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# fine tuning segment \n",
    "model.StartFineTuning(blocks_to_unfreeze=3)\n",
    "summary(model);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T20:57:16.055975Z",
     "start_time": "2025-04-08T20:57:16.045341Z"
    }
   },
   "id": "cf2f6fc74395ea60"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [56:03<00:00,  2.80s/it, Training Loss=0.194]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/3]\n",
      "        \t training loss: 0.1939756562568555,\n",
      "        \t validation loss: 0.2718391049901644,\n",
      "        \t Train Accuracy: 0.9234114289283752,\n",
      "        \t Val acc: 0.8854166865348816,\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 311/1200 [20:07<57:32,  3.88s/it, Training Loss=0.0623]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m train_swin(TrainLoader, ValLoader, model, EPOCHS\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n",
      "Cell \u001B[0;32mIn[34], line 31\u001B[0m, in \u001B[0;36mtrain_swin\u001B[0;34m(TrainLoader, ValLoader, model, EPOCHS)\u001B[0m\n\u001B[1;32m     28\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# predicting and training \u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m output \u001B[38;5;241m=\u001B[39m model(image)\n\u001B[1;32m     32\u001B[0m loss \u001B[38;5;241m=\u001B[39m lossfn(output\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m), label\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[1;32m     33\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[30], line 30\u001B[0m, in \u001B[0;36mSWIN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x): \n\u001B[0;32m---> 30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mswin(x)\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torchvision/models/swin_transformer.py:608\u001B[0m, in \u001B[0;36mSwinTransformer.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 608\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures(x)\n\u001B[1;32m    609\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(x)\n\u001B[1;32m    610\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpermute(x)\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torchvision/models/swin_transformer.py:453\u001B[0m, in \u001B[0;36mSwinTransformerBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor):\n\u001B[0;32m--> 453\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstochastic_depth(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(x)))\n\u001B[1;32m    454\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstochastic_depth(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(x)))\n\u001B[1;32m    455\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torchvision/models/swin_transformer.py:299\u001B[0m, in \u001B[0;36mShiftedWindowAttention.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;124;03m    x (Tensor): Tensor with layout of [B, H, W, C]\u001B[39;00m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;124;03m    Tensor with same layout as input, i.e. [B, H, W, C]\u001B[39;00m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    298\u001B[0m relative_position_bias \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_relative_position_bias()\n\u001B[0;32m--> 299\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m shifted_window_attention(\n\u001B[1;32m    300\u001B[0m     x,\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mqkv\u001B[38;5;241m.\u001B[39mweight,\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproj\u001B[38;5;241m.\u001B[39mweight,\n\u001B[1;32m    303\u001B[0m     relative_position_bias,\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size,\n\u001B[1;32m    305\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads,\n\u001B[1;32m    306\u001B[0m     shift_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshift_size,\n\u001B[1;32m    307\u001B[0m     attention_dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention_dropout,\n\u001B[1;32m    308\u001B[0m     dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout,\n\u001B[1;32m    309\u001B[0m     qkv_bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mqkv\u001B[38;5;241m.\u001B[39mbias,\n\u001B[1;32m    310\u001B[0m     proj_bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproj\u001B[38;5;241m.\u001B[39mbias,\n\u001B[1;32m    311\u001B[0m     training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining,\n\u001B[1;32m    312\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda/envs/EnvironmentTest/lib/python3.11/site-packages/torchvision/models/swin_transformer.py:179\u001B[0m, in \u001B[0;36mshifted_window_attention\u001B[0;34m(input, qkv_weight, proj_weight, relative_position_bias, window_size, num_heads, shift_size, attention_dropout, dropout, qkv_bias, proj_bias, logit_scale, training)\u001B[0m\n\u001B[1;32m    177\u001B[0m     length \u001B[38;5;241m=\u001B[39m qkv_bias\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m    178\u001B[0m     qkv_bias[length : \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m length]\u001B[38;5;241m.\u001B[39mzero_()\n\u001B[0;32m--> 179\u001B[0m qkv \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mlinear(x, qkv_weight, qkv_bias)\n\u001B[1;32m    180\u001B[0m qkv \u001B[38;5;241m=\u001B[39m qkv\u001B[38;5;241m.\u001B[39mreshape(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m), \u001B[38;5;241m3\u001B[39m, num_heads, C \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_heads)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m    181\u001B[0m q, k, v \u001B[38;5;241m=\u001B[39m qkv[\u001B[38;5;241m0\u001B[39m], qkv[\u001B[38;5;241m1\u001B[39m], qkv[\u001B[38;5;241m2\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = train_swin(TrainLoader, ValLoader, model, EPOCHS=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T22:42:15.999259Z",
     "start_time": "2025-04-08T20:57:30.383992Z"
    }
   },
   "id": "42abd06220b451a4"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "torch.save(model, './saved models/swin_finetuned.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T07:35:05.804823Z",
     "start_time": "2025-04-08T07:35:05.584993Z"
    }
   },
   "id": "463a1ac674fa3b6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d50b94502de477"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = torch.load('./saved models/swin_no_finetune.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:05:04.361397Z",
     "start_time": "2025-04-10T07:05:04.152339Z"
    }
   },
   "id": "b413bfb8da67d6f4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "testlink = \"datasets/30 k datapoints/test\"\n",
    "testset = CustomDataset(root= testlink, transform=swin_transforms)\n",
    "TestLoader = DataLoader(testset, shuffle=False, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T01:53:47.437070Z",
     "start_time": "2025-04-09T01:53:47.410791Z"
    }
   },
   "id": "b2c36a82be0d34d1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [13:28<00:00,  2.16s/it, Loss=0.306] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "running_loss = 0\n",
    "BATCH_SIZE = 32\n",
    "# for metrics\n",
    "accuracy = Accuracy(task='multiclass', num_classes=2).to(device=device)\n",
    "precision = Precision(task='multiclass', num_classes=2).to(device=device)\n",
    "recall = Recall(task='multiclass', num_classes=2).to(device=device)\n",
    "ConMat = ConfusionMatrix(task='multiclass', num_classes=2).to(device=device)\n",
    "\n",
    "# loss function \n",
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# testing phase\n",
    "TestLoader_tqdm = tqdm(TestLoader)\n",
    "model.eval()\n",
    "for image, label in TestLoader_tqdm:\n",
    "    image = image.to(device= device)\n",
    "    label = label.to(device=device)\n",
    "\n",
    "    output = model(image)\n",
    "\n",
    "    loss = lossfn(output, label.float())\n",
    "    running_loss += loss.item() / len(TestLoader)\n",
    "\n",
    "    TestLoader_tqdm.set_postfix({'Loss':running_loss})\n",
    "\n",
    "    accuracy.update(output, label.argmax(dim=1))\n",
    "    precision.update(output, label.argmax(dim=1))\n",
    "    recall.update(output, label.argmax(dim=1))\n",
    "    ConMat.update(output, label.argmax(dim=1))\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T02:07:50.617824Z",
     "start_time": "2025-04-09T01:54:21.987607Z"
    }
   },
   "id": "bdf78b481de5f112"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.921999990940094]\n",
      "    \t Test loss: 0.30621550742816206,\n",
      "    \t Precision: 0.921999990940094,\n",
      "    \t Recall: 0.921999990940094,\n",
      "    \t \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f'''Accuracy [{accuracy.compute()}]\n",
    "    \\t Test loss: {running_loss},\n",
    "    \\t Precision: {precision.compute()},\n",
    "    \\t Recall: {recall.compute()},\n",
    "    \\t \n",
    "        ''')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T02:07:50.653514Z",
     "start_time": "2025-04-09T02:07:50.619532Z"
    }
   },
   "id": "a6e620e0426434b8"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5549,  451],\n        [ 485, 5515]], device='mps:0')"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConMat.compute()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T02:07:50.654384Z",
     "start_time": "2025-04-09T02:07:50.643497Z"
    }
   },
   "id": "4c8f22e30388fd8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0e11cc6eb46d78f"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "link = './datasets/real life'\n",
    "BATCH_SIZE = 32\n",
    "randomTestSet = CustomDataset(root = link, transform=swin_transforms)\n",
    "TestLoader = DataLoader(randomTestSet, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:21:07.426802Z",
     "start_time": "2025-04-10T07:21:07.423527Z"
    }
   },
   "id": "b27e0cf8c8875bf8"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it, Loss=10.2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "running_loss = 0\n",
    "\n",
    "# for metrics\n",
    "accuracy = Accuracy(task='multiclass', num_classes=2).to(device=device)\n",
    "precision = Precision(task='multiclass', num_classes=2).to(device=device)\n",
    "recall = Recall(task='multiclass', num_classes=2).to(device=device)\n",
    "ConMat = ConfusionMatrix(task='multiclass', num_classes=2).to(device=device)\n",
    "\n",
    "accuracy.reset()\n",
    "precision.reset()\n",
    "recall.reset()\n",
    "ConMat.reset()\n",
    "# loss function \n",
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# testing phase\n",
    "TestLoader_tqdm = tqdm(TestLoader)\n",
    "model.eval()\n",
    "for idx, (image, label) in enumerate(TestLoader_tqdm):\n",
    "    image = image.to(device= device)\n",
    "    label = label.to(device=device)\n",
    "\n",
    "    output = model(image)\n",
    "\n",
    "    loss = lossfn(output, label.float())\n",
    "    running_loss += loss.item() / len(TestLoader)\n",
    "\n",
    "    TestLoader_tqdm.set_postfix({'Loss':running_loss})\n",
    "\n",
    "    accuracy.update(output, label.argmax(dim=1))\n",
    "    precision.update(output, label.argmax(dim=1))\n",
    "    recall.update(output, label.argmax(dim=1))\n",
    "    ConMat.update(output, label.argmax(dim=1))\n",
    "\n",
    "    if idx == 100:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:21:08.862757Z",
     "start_time": "2025-04-10T07:21:07.628074Z"
    }
   },
   "id": "724b8f915df6e52e"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.2857142984867096]\n",
      "    \t Test loss: 10.234702110290527,\n",
      "    \t Precision: 0.2857142984867096,\n",
      "    \t Recall: 0.2857142984867096,\n",
      "    \t \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f'''Accuracy [{accuracy.compute()}]\n",
    "    \\t Test loss: {running_loss},\n",
    "    \\t Precision: {precision.compute()},\n",
    "    \\t Recall: {recall.compute()},\n",
    "    \\t \n",
    "        ''')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:21:08.869972Z",
     "start_time": "2025-04-10T07:21:08.863087Z"
    }
   },
   "id": "7ee39c5ee016817f"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 0],\n        [5, 0]], device='mps:0')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConMat.compute()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T07:21:08.872844Z",
     "start_time": "2025-04-10T07:21:08.868443Z"
    }
   },
   "id": "863e18b277ef65e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "edaeea264c8c831a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
